{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32e6d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from operator import add as add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac6ac041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f76f82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature = 0) # I want to minimize hallucination - temperature = 0 makes the model output more deterministic \n",
    "\n",
    "# Our Embedding Model - has to also be compatible with the LLM\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "pdf_path = \"Stock_Market_Performance_2024.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc353d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF has been loaded and has 9 pages\n"
     ]
    }
   ],
   "source": [
    "# Safety measure I have put for debugging purposes :)\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "\n",
    "pdf_loader = PyPDFLoader(pdf_path) # This loads the PDF\n",
    "\n",
    "# Checks if the PDF is there\n",
    "try:\n",
    "    pages = pdf_loader.load()\n",
    "    print(f\"PDF has been loaded and has {len(pages)} pages\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF: {e}\")\n",
    "    raise\n",
    "\n",
    "# Chunking Process\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2d97b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Vector store directory: /Users/ashwanthfernando/code/ml-notebooks/agentic-ai/vector_store_ultimate_fix\n",
      "âœ… Directory is writable: True\n",
      "ðŸ“„ Processing 24 document chunks...\n",
      "âŒ Error setting up ChromaDB: \u001b[91mYou are using a deprecated configuration of Chroma.\n",
      "\n",
      "\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\n",
      "your Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/deployment/migration.\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "If you do have data you wish to migrate, we have a migration tool you can use in order to\n",
      "migrate your data to the new Chroma architecture.\n",
      "Please `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\n",
      "change how you construct your Chroma client.\n",
      "\n",
      "See https://docs.trychroma.com/deployment/migration for more information or join our discord at https://discord.gg/MMeYNTmh3x for help!\u001b[0m\n",
      "ðŸ“ Current working directory: /Users/ashwanthfernando/code/ml-notebooks/agentic-ai\n",
      "ðŸ“ Trying to write to: /Users/ashwanthfernando/code/ml-notebooks/agentic-ai/vector_store_ultimate_fix\n",
      "ðŸ“‚ Path exists: True\n",
      "âœï¸  Path is writable: True\n",
      "\n",
      "ðŸ”„ Trying alternative approach with in-memory database...\n",
      "âœ… In-memory vector store created successfully!\n"
     ]
    }
   ],
   "source": [
    "# ULTIMATE FIX - Create vector store with explicit client settings\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Split the documents first\n",
    "pages_split = text_splitter.split_documents(pages)\n",
    "\n",
    "# Use current working directory which is guaranteed to be writable\n",
    "vector_store_dir = Path.cwd() / \"vector_store_ultimate_fix\"\n",
    "collection_name = \"stock_market\"\n",
    "\n",
    "# Clean up any existing database that might be corrupted\n",
    "if vector_store_dir.exists():\n",
    "    shutil.rmtree(vector_store_dir, ignore_errors=True)\n",
    "\n",
    "vector_store_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"âœ¨ Vector store directory: {vector_store_dir}\")\n",
    "print(f\"âœ… Directory is writable: {os.access(vector_store_dir, os.W_OK)}\")\n",
    "print(f\"ðŸ“„ Processing {len(pages_split)} document chunks...\")\n",
    "\n",
    "try:\n",
    "    # Create ChromaDB client with explicit settings to avoid tenant issues\n",
    "    client_settings = Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=str(vector_store_dir),\n",
    "        anonymized_telemetry=False\n",
    "    )\n",
    "    \n",
    "    # Create the vector store with explicit client settings\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=pages_split,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=str(vector_store_dir),\n",
    "        collection_name=collection_name,\n",
    "        client_settings=client_settings\n",
    "    )\n",
    "    \n",
    "    print(f\"ðŸŽ‰ Successfully created ChromaDB vector store!\")\n",
    "    print(f\"ðŸ“Š Stored {len(pages_split)} document chunks\")\n",
    "    \n",
    "    # Test a simple query to verify it works\n",
    "    test_query = \"What is the stock market performance?\"\n",
    "    results = vectorstore.similarity_search(test_query, k=2)\n",
    "    print(f\"âœ… Vector store is working! Found {len(results)} relevant documents for test query.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error setting up ChromaDB: {str(e)}\")\n",
    "    print(f\"ðŸ“ Current working directory: {Path.cwd()}\")\n",
    "    print(f\"ðŸ“ Trying to write to: {vector_store_dir}\")\n",
    "    print(f\"ðŸ“‚ Path exists: {vector_store_dir.exists()}\")\n",
    "    print(f\"âœï¸  Path is writable: {os.access(vector_store_dir, os.W_OK)}\")\n",
    "    \n",
    "    # If still failing, try alternative approach\n",
    "    print(\"\\nðŸ”„ Trying alternative approach with in-memory database...\")\n",
    "    try:\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=pages_split,\n",
    "            embedding=embeddings,\n",
    "            collection_name=collection_name + \"_memory\"\n",
    "            # No persist_directory = in-memory only\n",
    "        )\n",
    "        print(\"âœ… In-memory vector store created successfully!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Alternative approach also failed: {str(e2)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c3a02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create our retriever \n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5} # K is the amount of chunks to return\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ebcae9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retriever_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool searches and returns the information from the Stock Market Performance 2024 document.\n",
    "    \"\"\"\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    if not docs:\n",
    "        return \"I found no relevant information in the Stock Market Performance 2024 document.\"\n",
    "    \n",
    "    results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        results.append(f\"Document {i+1}:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "tools = [retriever_tool]\n",
    "\n",
    "llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8025b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbe188c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Check if the last message contains tool calls.\"\"\"\n",
    "    result = state['messages'][-1]\n",
    "    return hasattr(result, 'tool_calls') and len(result.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "63e0a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an intelligent AI assistant who answers questions about Stock Market Performance in 2024 based on the PDF document loaded into your knowledge base.\n",
    "Use the retriever tool available to answer questions about the stock market performance data. You can make multiple calls if needed.\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "Please always cite the specific parts of the documents you use in your answers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d19e6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_dict = {our_tool.name: our_tool for our_tool in tools} # Creating a dictionary of our tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c64fd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Agent\n",
    "def call_llm(state: AgentState) -> AgentState:\n",
    "    \"\"\"Function to call the LLM with the current state.\"\"\"\n",
    "    messages = list(state['messages'])\n",
    "    messages = [SystemMessage(content=system_prompt)] + messages\n",
    "    message = llm.invoke(messages)\n",
    "    return {'messages': [message]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ec79122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever Agent\n",
    "def take_action(state: AgentState) -> AgentState:\n",
    "    \"\"\"Execute tool calls from the LLM's response.\"\"\"\n",
    "\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    for t in tool_calls:\n",
    "        print(f\"Calling Tool: {t['name']} with query: {t['args'].get('query', 'No query provided')}\")\n",
    "        \n",
    "        if not t['name'] in tools_dict: # Checks if a valid tool is present\n",
    "            print(f\"\\nTool: {t['name']} does not exist.\")\n",
    "            result = \"Incorrect Tool Name, Please Retry and Select tool from List of Available tools.\"\n",
    "        \n",
    "        else:\n",
    "            result = tools_dict[t['name']].invoke(t['args'].get('query', ''))\n",
    "            print(f\"Result length: {len(str(result))}\")\n",
    "            \n",
    "        # Appends the Tool Message\n",
    "        results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "\n",
    "    print(\"Tools Execution Complete. Back to the model!\")\n",
    "    return {'messages': results}\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"retriever_agent\", take_action)\n",
    "graph.add_node(\"llm\", call_llm)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    should_continue,\n",
    "    {True: \"retriever_agent\", False: END}\n",
    ")\n",
    "graph.add_edge(\"retriever_agent\", \"llm\")\n",
    "graph.set_entry_point(\"llm\")\n",
    "\n",
    "rag_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "69f2d01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAG AGENT===\n",
      "Calling Tool: retriever_tool with query: stock market performance 2024\n",
      "Result length: 4664\n",
      "Tools Execution Complete. Back to the model!\n",
      "\n",
      "=== ANSWER ===\n",
      "The PDF document provides a detailed overview of the stock market performance in 2024, highlighting several key points:\n",
      "\n",
      "1. **Overall Market Performance**: The U.S. stock market had a strong year in 2024, with the S&P 500 index delivering a total return of approximately 25%, marking the second consecutive year of over 20% returns. The Nasdaq Composite outperformed the broader market with a nearly 29% increase (Document 1).\n",
      "\n",
      "2. **Sector Performance**: The technology sector dominated the market, with mega-cap technology stocks leading the rally. A group of companies known as the \"Magnificent 7\" (Apple, Microsoft, Alphabet, Amazon, Meta, Nvidia, and Tesla) surged by roughly 64-67% on average, contributing significantly to the S&P 500's gains (Document 4).\n",
      "\n",
      "3. **Market Concentration**: The gains were not evenly distributed across the market, with smaller-cap stocks like the S&P 500 Equal-Weight index and the Russell 2000 rising only about 10-11%. The market rally was concentrated in a few large technology companies (Document 1).\n",
      "\n",
      "4. **Investor Sentiment**: The year was characterized by a bullish sentiment driven by technology and growth stocks, with a focus on transformative technologies such as artificial intelligence, cloud computing, and quantum technology (Document 3).\n",
      "\n",
      "5. **Valuation Concerns**: By the end of 2024, many leading stocks were trading at high valuations, reflecting significant optimism for future growth. This raised concerns about potential corrections given the rapid rise in stock prices (Document 2).\n",
      "\n",
      "6. **Individual Stock Performances**: Notable performances included Meta's 72% stock gain and Tesla's approximately 63% increase, despite some volatility during the year (Documents 4 and 5).\n",
      "\n",
      "Overall, 2024 was a year of exceptional stock market performance, heavily influenced by the technology sector and marked by significant gains in major indices.\n",
      "Calling Tool: retriever_tool with query: S&P 500 return 2024\n",
      "Result length: 4654\n",
      "Tools Execution Complete. Back to the model!\n",
      "\n",
      "=== ANSWER ===\n",
      "The S&P 500 delivered a total return of approximately 25% in 2024, with around 23% in price terms. This marked the second consecutive year of over 20% returns for the S&P 500, a feat not observed since the late 1990s (Document 1).\n",
      "\n",
      "=== ANSWER ===\n",
      "Sure, I can provide just the percentage number if you specify what specific data or metric you are interested in. Please let me know what you would like to know about the Stock Market Performance in 2024.\n",
      "Calling Tool: retriever_tool with query: S&P 500 return percentage 2024\n",
      "Result length: 4842\n",
      "Tools Execution Complete. Back to the model!\n",
      "\n",
      "=== ANSWER ===\n",
      "The S&P 500 delivered roughly a 25% total return for the year 2024, with around +23% in price terms. This marked the second consecutive year of over 20% returns for the S&P 500, a feat not observed since the late 1990s (Document 1).\n"
     ]
    }
   ],
   "source": [
    "def running_agent():\n",
    "    print(\"\\n=== RAG AGENT===\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nWhat is your question: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            break\n",
    "            \n",
    "        messages = [HumanMessage(content=user_input)] # converts back to a HumanMessage type\n",
    "\n",
    "        result = rag_agent.invoke({\"messages\": messages})\n",
    "        \n",
    "        print(\"\\n=== ANSWER ===\")\n",
    "        print(result['messages'][-1].content)\n",
    "\n",
    "running_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d560f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
