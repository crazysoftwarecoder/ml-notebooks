{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "g6foxh33fgd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StateGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m app\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create the agent\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m property_price_agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_property_price_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mcreate_property_price_agent\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create and compile the property price fetcher agent\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create the graph\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m workflow \u001b[38;5;241m=\u001b[39m \u001b[43mStateGraph\u001b[49m(AgentState)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Add nodes\u001b[39;00m\n\u001b[1;32m      9\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrape_websites\u001b[39m\u001b[38;5;124m\"\u001b[39m, scrape_websites_node)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StateGraph' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the agent workflow\n",
    "def create_property_price_agent():\n",
    "    \"\"\"Create and compile the property price fetcher agent\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"scrape_websites\", scrape_websites_node)\n",
    "    workflow.add_node(\"extract_prices\", extract_prices_node)\n",
    "    workflow.add_node(\"calculate_total\", calculate_total_node)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"scrape_websites\")\n",
    "    workflow.add_edge(\"scrape_websites\", \"extract_prices\")\n",
    "    workflow.add_edge(\"extract_prices\", \"calculate_total\")\n",
    "    workflow.add_edge(\"calculate_total\", END)\n",
    "    \n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the agent\n",
    "property_price_agent = create_property_price_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4p4183o7c89",
   "source": "# Property Price Fetcher Agent\n\nThis notebook implements an agent that fetches property prices from websites by:\n1. Accepting an address prompt\n2. Scraping HTML from property websites\n3. Extracting specific div content\n4. Using an LLM to parse prices from the HTML\n5. Summing up the total property prices",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "injlqi9vk6l",
   "source": "# Import required libraries\nimport os\nfrom typing import TypedDict, List, Dict, Any\nimport requests\nfrom bs4 import BeautifulSoup\nimport json\nfrom langgraph.graph import StateGraph, END\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage, SystemMessage\nimport re\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\nprint(\"Libraries imported successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3xgvl12819l",
   "source": "# Define the state for our agent\nclass AgentState(TypedDict):\n    address: str\n    websites: List[Dict[str, Any]]  # Contains url, div_selector, html_content\n    extracted_prices: List[float]\n    total_price: float\n    messages: List[str]",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "csdd4ctd2zi",
   "source": "# Initialize the LLM using OpenAI (API key loaded from .env)\ntry:\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    print(\"LLM initialized successfully using OpenAI!\")\nexcept Exception as e:\n    print(f\"Error initializing LLM: {e}\")\n    print(\"Please ensure OPENAI_API_KEY is set in your .env file\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "qpv86u0hxai",
   "source": "# Function to scrape HTML content from websites\ndef scrape_website(url: str, div_selector: str = None) -> Dict[str, Any]:\n    \"\"\"\n    Scrape website and extract specific div content if selector provided\n    \"\"\"\n    try:\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n        }\n        response = requests.get(url, headers=headers, timeout=10)\n        response.raise_for_status()\n        \n        soup = BeautifulSoup(response.text, 'html.parser')\n        \n        # If specific div selector provided, extract that content\n        if div_selector:\n            # Handle different selector types (id, class, etc.)\n            if div_selector.startswith('#'):\n                # ID selector\n                element = soup.find(id=div_selector[1:])\n            elif div_selector.startswith('.'):\n                # Class selector\n                element = soup.find(class_=div_selector[1:])\n            else:\n                # Tag selector or complex selector\n                element = soup.select_one(div_selector)\n            \n            if element:\n                content = str(element)\n            else:\n                content = f\"No element found with selector: {div_selector}\"\n        else:\n            # Return full HTML if no selector specified\n            content = str(soup)\n        \n        return {\n            \"url\": url,\n            \"selector\": div_selector,\n            \"content\": content,\n            \"status\": \"success\"\n        }\n        \n    except Exception as e:\n        return {\n            \"url\": url,\n            \"selector\": div_selector,\n            \"content\": None,\n            \"status\": \"error\",\n            \"error\": str(e)\n        }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jjt0hw7xpc",
   "source": "# Function to extract prices from HTML using LLM\ndef extract_prices_with_llm(html_content: str, address: str) -> List[float]:\n    \"\"\"\n    Use LLM to extract property prices from HTML content\n    \"\"\"\n    if not html_content:\n        return []\n    \n    system_prompt = \"\"\"You are a property price extraction expert. Your task is to extract property prices from HTML content.\n    \n    Rules:\n    1. Look for price patterns like $XXX,XXX or £XXX,XXX or €XXX,XXX\n    2. Extract ONLY property prices, not other prices like fees or taxes\n    3. Return prices as a JSON array of numbers (without currency symbols or commas)\n    4. If no prices found, return empty array []\n    5. Focus on the main property listing price\n    \"\"\"\n    \n    user_prompt = f\"\"\"Extract property prices for the address: {address}\n    \n    From the following HTML content:\n    {html_content[:3000]}  # Limiting to avoid token limits\n    \n    Return ONLY a JSON array of price numbers, e.g., [450000, 525000]\n    \"\"\"\n    \n    try:\n        response = llm.invoke([\n            SystemMessage(content=system_prompt),\n            HumanMessage(content=user_prompt)\n        ])\n        \n        # Extract JSON array from response\n        content = response.content\n        # Try to find JSON array pattern\n        json_match = re.search(r'\\[[\\d,\\s]*\\]', content)\n        if json_match:\n            prices_str = json_match.group()\n            prices = json.loads(prices_str)\n            return [float(price) for price in prices]\n        else:\n            # Try to extract individual numbers\n            numbers = re.findall(r'\\d+(?:,\\d{3})*(?:\\.\\d+)?', content)\n            prices = []\n            for num in numbers:\n                clean_num = float(num.replace(',', ''))\n                if clean_num > 10000:  # Assume property prices are > $10k\n                    prices.append(clean_num)\n            return prices\n            \n    except Exception as e:\n        print(f\"Error extracting prices: {e}\")\n        return []",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "n7ps577crpg",
   "source": "# Define the agent nodes\n\ndef scrape_websites_node(state: AgentState) -> AgentState:\n    \"\"\"Node to scrape websites for property data\"\"\"\n    messages = state.get(\"messages\", [])\n    messages.append(f\"Scraping websites for address: {state['address']}\")\n    \n    scraped_data = []\n    for website in state[\"websites\"]:\n        result = scrape_website(website[\"url\"], website.get(\"div_selector\"))\n        scraped_data.append(result)\n        \n        if result[\"status\"] == \"success\":\n            messages.append(f\"Successfully scraped {website['url']}\")\n        else:\n            messages.append(f\"Failed to scrape {website['url']}: {result.get('error', 'Unknown error')}\")\n    \n    state[\"websites\"] = scraped_data\n    state[\"messages\"] = messages\n    return state\n\ndef extract_prices_node(state: AgentState) -> AgentState:\n    \"\"\"Node to extract prices from scraped HTML using LLM\"\"\"\n    messages = state.get(\"messages\", [])\n    all_prices = []\n    \n    for website in state[\"websites\"]:\n        if website[\"status\"] == \"success\" and website[\"content\"]:\n            prices = extract_prices_with_llm(website[\"content\"], state[\"address\"])\n            all_prices.extend(prices)\n            \n            if prices:\n                messages.append(f\"Found {len(prices)} price(s) from {website['url']}: {prices}\")\n            else:\n                messages.append(f\"No prices found from {website['url']}\")\n    \n    state[\"extracted_prices\"] = all_prices\n    state[\"messages\"] = messages\n    return state\n\ndef calculate_total_node(state: AgentState) -> AgentState:\n    \"\"\"Node to calculate total of all extracted prices\"\"\"\n    messages = state.get(\"messages\", [])\n    \n    if state[\"extracted_prices\"]:\n        total = sum(state[\"extracted_prices\"])\n        state[\"total_price\"] = total\n        messages.append(f\"Total property price: ${total:,.2f}\")\n        messages.append(f\"Average price: ${total/len(state['extracted_prices']):,.2f}\")\n    else:\n        state[\"total_price\"] = 0\n        messages.append(\"No prices were found to calculate total\")\n    \n    state[\"messages\"] = messages\n    return state",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3s2ma61xsf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the agent\n",
    "def fetch_property_prices(address: str, websites: List[Dict[str, str]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch property prices for a given address from specified websites\n",
    "    \n",
    "    Args:\n",
    "        address: The property address to search for\n",
    "        websites: List of dicts with 'url' and optional 'div_selector' keys\n",
    "        \n",
    "    Returns:\n",
    "        Dict with results including total price, individual prices, and messages\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_state = {\n",
    "        \"address\": address,\n",
    "        \"websites\": websites,\n",
    "        \"extracted_prices\": [],\n",
    "        \"total_price\": 0.0,\n",
    "        \"messages\": []\n",
    "    }\n",
    "    \n",
    "    # Run the agent\n",
    "    result = property_price_agent.invoke(initial_state)\n",
    "    \n",
    "    # Format the output\n",
    "    output = {\n",
    "        \"address\": address,\n",
    "        \"total_price\": result[\"total_price\"],\n",
    "        \"individual_prices\": result[\"extracted_prices\"],\n",
    "        \"num_prices_found\": len(result[\"extracted_prices\"]),\n",
    "        \"messages\": result[\"messages\"]\n",
    "    }\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "syi1up1tyg",
   "metadata": {},
   "outputs": [],
   "source": "# Example: Using the Agent for \"74 hilda rd baulkham hills nsw\"\n# Domain.com.au may block direct scraping, so this shows the configuration\n\naddress = \"74 hilda rd baulkham hills nsw\"\nwebsites = [\n    {\n        \"url\": \"https://www.domain.com.au/property-profile/74-hilda-road-baulkham-hills-nsw-2153\",\n        \"div_selector\": \"[data-testid='estimate-card']\"\n    }\n]\n\nprint(f\"Configuration for: {address}\")\nprint(f\"Website: {websites[0]['url']}\")\nprint(f\"Target element: {websites[0]['div_selector']}\")\n\n# Example usage (Domain.com.au may block scraping due to anti-bot measures)\n# Uncomment to try:\n\"\"\"\nresult = fetch_property_prices(address, websites)\nprint(\"\\\\n=== Results ===\")\nprint(f\"Address: {result['address']}\")\nprint(f\"Total Price: ${result['total_price']:,.2f}\")\nprint(f\"Individual prices: {result['individual_prices']}\")\nfor msg in result['messages']:\n    print(f\"- {msg}\")\n\"\"\"\n\n# Demonstration with mock Domain.com.au data\nprint(\"\\\\n\" + \"=\"*40)\nprint(\"MOCK DEMONSTRATION\")\nprint(\"=\"*40)\n\nmock_domain_html = \"\"\"\n<div data-testid=\"estimate-card\" class=\"estimate-card\">\n    <h3>Property Estimate</h3>\n    <div class=\"price-range\">\n        <span class=\"estimate-low\">$1,180,000</span>\n        <span class=\"estimate-high\">$1,290,000</span>\n    </div>\n    <div class=\"confidence\">High confidence estimate</div>\n</div>\n\"\"\"\n\n# Test with mock data\nprices = extract_prices_with_llm(mock_domain_html, address)\nprint(f\"Mock extraction results: {prices}\")\nif prices:\n    print(f\"Price range: ${min(prices):,.2f} - ${max(prices):,.2f}\")\n    print(f\"Average estimate: ${sum(prices)/len(prices):,.2f}\")\n\nprint(\"\\\\nNote: Many property websites use anti-scraping measures.\")\nprint(\"For production use, consider using official APIs or web scraping services.\")"
  },
  {
   "cell_type": "markdown",
   "id": "6j3hzqqb1jh",
   "metadata": {},
   "source": "## How to Use This Agent\n\n1. **Environment Setup:**\n   - The agent uses OpenAI API key from your `.env` file\n   - Make sure your `.env` file contains: `OPENAI_API_KEY=your-key-here`\n\n2. **Prepare website configurations:**\n   - Provide URLs of property listing websites\n   - Specify div selectors for price elements (optional)\n   - Use CSS selectors like `.class-name`, `#id-name`, or `div.specific-class`\n\n3. **Run the agent:**\n   ```python\n   websites = [\n       {\"url\": \"https://property-site.com/...\", \"div_selector\": \".price\"},\n       {\"url\": \"https://another-site.com/...\", \"div_selector\": \"#listing-price\"}\n   ]\n   \n   result = fetch_property_prices(\"123 Main St, City, State\", websites)\n   ```\n\n4. **The agent will:**\n   - Scrape each website\n   - Extract HTML content from specified divs\n   - Use LLM to identify and parse property prices\n   - Sum all found prices\n   - Return detailed results with individual prices and total"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twiesfuthnq",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwanthfernando/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m     messages: List[\u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Initialize the LLM (you'll need to set your API key)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# os.environ[\"GOOGLE_API_KEY\"] = \"your-api-key-here\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-pro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Function to scrape HTML content from websites\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mscrape_website\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, div_selector: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:1189\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         suggestion \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1183\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Did you mean: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1184\u001b[0m         )\n\u001b[1;32m   1185\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1186\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1188\u001b[0m         )\n\u001b[0;32m-> 1189\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:1248\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         google_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoogle_api_key\n\u001b[1;32m   1247\u001b[0m transport: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport\n\u001b[0;32m-> 1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mgenaix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/langchain_google_genai/_genai_extension.py:276\u001b[0m, in \u001b[0;36mbuild_generative_service\u001b[0;34m(credentials, api_key, client_options, client_info, transport)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_generative_service\u001b[39m(\n\u001b[1;32m    263\u001b[0m     credentials: Optional[credentials\u001b[38;5;241m.\u001b[39mCredentials] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    264\u001b[0m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m v1betaGenerativeServiceClient:\n\u001b[1;32m    269\u001b[0m     config \u001b[38;5;241m=\u001b[39m _prepare_config(\n\u001b[1;32m    270\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m    271\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m         client_info\u001b[38;5;241m=\u001b[39mclient_info,\n\u001b[1;32m    275\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:697\u001b[0m, in \u001b[0;36mGenerativeServiceClient.__init__\u001b[0;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[1;32m    688\u001b[0m     transport_init: Union[\n\u001b[1;32m    689\u001b[0m         Type[GenerativeServiceTransport],\n\u001b[1;32m    690\u001b[0m         Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, GenerativeServiceTransport],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, GenerativeServiceTransport], transport)\n\u001b[1;32m    695\u001b[0m     )\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport):\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER\u001b[38;5;241m.\u001b[39misEnabledFor(\n\u001b[1;32m    711\u001b[0m         std_logging\u001b[38;5;241m.\u001b[39mDEBUG\n\u001b[1;32m    712\u001b[0m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:234\u001b[0m, in \u001b[0;36mGenerativeServiceGrpcTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[1;32m    230\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m    231\u001b[0m             )\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:100\u001b[0m, in \u001b[0;36mGenerativeServiceTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[1;32m     97\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[0;32m--> 100\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/code/ml-notebooks/mypropertypriceagent/propertyenv/lib/python3.9/site-packages/google/auth/_default.py:685\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    677\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    678\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    680\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    681\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    682\u001b[0m             )\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "# First, let's run all the code cells in order to set up the notebook\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import re\n",
    "\n",
    "# Define the state for our agent\n",
    "class AgentState(TypedDict):\n",
    "    address: str\n",
    "    websites: List[Dict[str, Any]]  # Contains url, div_selector, html_content\n",
    "    extracted_prices: List[float]\n",
    "    total_price: float\n",
    "    messages: List[str]\n",
    "\n",
    "# Initialize the LLM (you'll need to set your API key)\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-api-key-here\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)\n",
    "\n",
    "# Function to scrape HTML content from websites\n",
    "def scrape_website(url: str, div_selector: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Scrape website and extract specific div content if selector provided\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # If specific div selector provided, extract that content\n",
    "        if div_selector:\n",
    "            # Handle different selector types (id, class, etc.)\n",
    "            if div_selector.startswith('#'):\n",
    "                # ID selector\n",
    "                element = soup.find(id=div_selector[1:])\n",
    "            elif div_selector.startswith('.'):\n",
    "                # Class selector\n",
    "                element = soup.find(class_=div_selector[1:])\n",
    "            else:\n",
    "                # Tag selector or complex selector\n",
    "                element = soup.select_one(div_selector)\n",
    "            \n",
    "            if element:\n",
    "                content = str(element)\n",
    "            else:\n",
    "                content = f\"No element found with selector: {div_selector}\"\n",
    "        else:\n",
    "            # Return full HTML if no selector specified\n",
    "            content = str(soup)\n",
    "        \n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"selector\": div_selector,\n",
    "            \"content\": content,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"selector\": div_selector,\n",
    "            \"content\": None,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Function to extract prices from HTML using LLM\n",
    "def extract_prices_with_llm(html_content: str, address: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Use LLM to extract property prices from HTML content\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        return []\n",
    "    \n",
    "    system_prompt = \"\"\"You are a property price extraction expert. Your task is to extract property prices from HTML content.\n",
    "    \n",
    "    Rules:\n",
    "    1. Look for price patterns like $XXX,XXX or £XXX,XXX or €XXX,XXX\n",
    "    2. Extract ONLY property prices, not other prices like fees or taxes\n",
    "    3. Return prices as a JSON array of numbers (without currency symbols or commas)\n",
    "    4. If no prices found, return empty array []\n",
    "    5. Focus on the main property listing price\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Extract property prices for the address: {address}\n",
    "    \n",
    "    From the following HTML content:\n",
    "    {html_content[:3000]}  # Limiting to avoid token limits\n",
    "    \n",
    "    Return ONLY a JSON array of price numbers, e.g., [450000, 525000]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ])\n",
    "        \n",
    "        # Extract JSON array from response\n",
    "        content = response.content\n",
    "        # Try to find JSON array pattern\n",
    "        json_match = re.search(r'\\[[\\d,\\s]*\\]', content)\n",
    "        if json_match:\n",
    "            prices_str = json_match.group()\n",
    "            prices = json.loads(prices_str)\n",
    "            return [float(price) for price in prices]\n",
    "        else:\n",
    "            # Try to extract individual numbers\n",
    "            numbers = re.findall(r'\\d+(?:,\\d{3})*(?:\\.\\d+)?', content)\n",
    "            prices = []\n",
    "            for num in numbers:\n",
    "                clean_num = float(num.replace(',', ''))\n",
    "                if clean_num > 10000:  # Assume property prices are > $10k\n",
    "                    prices.append(clean_num)\n",
    "            return prices\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting prices: {e}\")\n",
    "        return []\n",
    "\n",
    "# Define the agent nodes\n",
    "\n",
    "def scrape_websites_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Node to scrape websites for property data\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    messages.append(f\"Scraping websites for address: {state['address']}\")\n",
    "    \n",
    "    scraped_data = []\n",
    "    for website in state[\"websites\"]:\n",
    "        result = scrape_website(website[\"url\"], website.get(\"div_selector\"))\n",
    "        scraped_data.append(result)\n",
    "        \n",
    "        if result[\"status\"] == \"success\":\n",
    "            messages.append(f\"Successfully scraped {website['url']}\")\n",
    "        else:\n",
    "            messages.append(f\"Failed to scrape {website['url']}: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    state[\"websites\"] = scraped_data\n",
    "    state[\"messages\"] = messages\n",
    "    return state\n",
    "\n",
    "def extract_prices_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Node to extract prices from scraped HTML using LLM\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    all_prices = []\n",
    "    \n",
    "    for website in state[\"websites\"]:\n",
    "        if website[\"status\"] == \"success\" and website[\"content\"]:\n",
    "            prices = extract_prices_with_llm(website[\"content\"], state[\"address\"])\n",
    "            all_prices.extend(prices)\n",
    "            \n",
    "            if prices:\n",
    "                messages.append(f\"Found {len(prices)} price(s) from {website['url']}: {prices}\")\n",
    "            else:\n",
    "                messages.append(f\"No prices found from {website['url']}\")\n",
    "    \n",
    "    state[\"extracted_prices\"] = all_prices\n",
    "    state[\"messages\"] = messages\n",
    "    return state\n",
    "\n",
    "def calculate_total_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Node to calculate total of all extracted prices\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    if state[\"extracted_prices\"]:\n",
    "        total = sum(state[\"extracted_prices\"])\n",
    "        state[\"total_price\"] = total\n",
    "        messages.append(f\"Total property price: ${total:,.2f}\")\n",
    "        messages.append(f\"Average price: ${total/len(state['extracted_prices']):,.2f}\")\n",
    "    else:\n",
    "        state[\"total_price\"] = 0\n",
    "        messages.append(\"No prices were found to calculate total\")\n",
    "    \n",
    "    state[\"messages\"] = messages\n",
    "    return state\n",
    "\n",
    "# Create the agent workflow\n",
    "def create_property_price_agent():\n",
    "    \"\"\"Create and compile the property price fetcher agent\"\"\"\n",
    "    \n",
    "    # Create the graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"scrape_websites\", scrape_websites_node)\n",
    "    workflow.add_node(\"extract_prices\", extract_prices_node)\n",
    "    workflow.add_node(\"calculate_total\", calculate_total_node)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"scrape_websites\")\n",
    "    workflow.add_edge(\"scrape_websites\", \"extract_prices\")\n",
    "    workflow.add_edge(\"extract_prices\", \"calculate_total\")\n",
    "    workflow.add_edge(\"calculate_total\", END)\n",
    "    \n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the agent\n",
    "property_price_agent = create_property_price_agent()\n",
    "\n",
    "# Main function to run the agent\n",
    "def fetch_property_prices(address: str, websites: List[Dict[str, str]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch property prices for a given address from specified websites\n",
    "    \n",
    "    Args:\n",
    "        address: The property address to search for\n",
    "        websites: List of dicts with 'url' and optional 'div_selector' keys\n",
    "        \n",
    "    Returns:\n",
    "        Dict with results including total price, individual prices, and messages\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_state = {\n",
    "        \"address\": address,\n",
    "        \"websites\": websites,\n",
    "        \"extracted_prices\": [],\n",
    "        \"total_price\": 0.0,\n",
    "        \"messages\": []\n",
    "    }\n",
    "    \n",
    "    # Run the agent\n",
    "    result = property_price_agent.invoke(initial_state)\n",
    "    \n",
    "    # Format the output\n",
    "    output = {\n",
    "        \"address\": address,\n",
    "        \"total_price\": result[\"total_price\"],\n",
    "        \"individual_prices\": result[\"extracted_prices\"],\n",
    "        \"num_prices_found\": len(result[\"extracted_prices\"]),\n",
    "        \"messages\": result[\"messages\"]\n",
    "    }\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test that everything is set up correctly\n",
    "print(\"Property Price Fetcher Agent initialized successfully!\")\n",
    "print(f\"Agent created: {property_price_agent is not None}\")\n",
    "print(f\"fetch_property_prices function ready: {fetch_property_prices is not None}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propertyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}